# /// script
# requires-python = ">=3.10"
# dependencies = [
#     "openai",
# ]
# ///

import os
import json
import sys
import time
from openai import OpenAI
import re

# ==========================================
# é…ç½®åŒºåŸŸ
# ==========================================
# API_KEY = os.getenv("sk-c03c16157366414db39385f6637105b4")
API_KEY="sk-c03c16157366414db39385f6637105b4"
BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
# å…è®¸ä»ç¯å¢ƒå˜é‡è¦†ç›–æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º deepseek-chat
MODEL_NAME = os.getenv("DEEPSEEK_MODEL_NAME", "deepseek-chat")

if not API_KEY:
    print("âŒ Error: è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY")
    sys.exit(1)

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

class LongArticleAgent:
    def __init__(self, topic):
        self.topic = topic
        self.outline = []
        self.articles = []

    def step1_generate_outline(self):
        """Step 1: ç”Ÿæˆç« èŠ‚å¤§çº²"""
        print(f"ğŸ“‹ æ­£åœ¨è§„åˆ’ä¸»é¢˜: {self.topic}...")

        # TODO: ç¼–å†™ Prompt è®©æ¨¡å‹ç”Ÿæˆçº¯ JSON åˆ—è¡¨
        prompt = (
            f"è¯·ä¸ºä¸»é¢˜ã€Š{self.topic}ã€‹è®¾è®¡ä¸€ä¸ªé•¿æ–‡å¤§çº²ï¼Œè§„åˆ’ 14-16 ä¸ªéƒ¨åˆ†ã€‚"
            "è¦æ±‚ï¼š\n"
            "1. è¾“å‡ºå¿…é¡»æ˜¯çº¯ JSON æ ¼å¼ã€‚\n"
            "2. ç»“æ„ä¸ºä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« 'title' (æ ‡é¢˜) å’Œ 'instruction' (æœ¬æ®µè½çš„è¯¦ç»†å†™ä½œæŒ‡å¯¼)ã€‚\n"
            "3. é€»è¾‘è¦è¿è´¯ï¼Œå±‚å±‚é€’è¿›ã€‚"
        )
        
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,  # ä½¿ç”¨é…ç½®çš„æ¨¡å‹å
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†™ä½œè§„åˆ’å¸ˆï¼Œåªè¾“å‡º JSON Arrayã€‚"},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.7
            )
            content = response.choices[0].message.content
            
            # TODO: è§£æè¿”å›çš„ JSON å†…å®¹åˆ° self.outline

            # å…¼å®¹ DeepSeek å¯èƒ½è¿”å›çš„ Markdown ä»£ç å—æ ¼å¼
            # -----------------------------------------------------------
            # æ¸…æ´— contentï¼Œé˜²æ­¢æ¨¡å‹è¿”å› ```json ... ```
            if "```" in content:
                content = re.sub(r"```json|```", "", content).strip()


            data = json.loads(content)
            
            # ç®€å•çš„å®¹é”™é€»è¾‘ç¤ºä¾‹ï¼ˆå€™é€‰äººéœ€è¦å®Œå–„ï¼‰
            # å…¼å®¹æ€§å¤„ç†ï¼šæ¨¡å‹å¯èƒ½è¿”å› {"chapters": [...]} ä¹Ÿå¯èƒ½ç›´æ¥è¿”å› [...]
            if isinstance(data, list):
                self.outline = data
            elif isinstance(data, dict):
                # å¯»æ‰¾å­—å…¸é‡Œç¬¬ä¸€ä¸ªæ˜¯ list çš„ value
                for key, value in data.items():
                    if isinstance(value, list):
                        self.outline = value
                        break
            
            if not self.outline:
                raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„å¤§çº²åˆ—è¡¨")

            # print(f"âœ… å¤§çº²å·²ç”Ÿæˆ: {self.outline}")
            print(f"âœ… å¤§çº²å·²ç”Ÿæˆ (å…±{len(self.outline)}éƒ¨åˆ†):")

        except Exception as e:
            print(f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥: {e}")
            print(f"Raw Content: {content if 'content' in locals() else 'None'}")
            sys.exit(1)

    def step2_generate_content_loop(self):
        """Step 2: å¾ªç¯ç”Ÿæˆå†…å®¹ï¼Œå¹¶ç»´æŠ¤ Context"""
        if not self.outline:
            return

        # å‡†å¤‡å…¨å±€ä¿¡æ¯ï¼ˆGlobal Stateï¼‰ï¼Œè®©æ¨¡å‹çŸ¥é“æ•´ä½“åœ°å›¾ï¼Œé˜²æ­¢è·‘é¢˜
        outline_str = "\n".join([f"{i + 1}. {item.get('title')}" for i, item in enumerate(self.outline)])
        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡æ‘˜è¦
        previous_summary = "æ–‡ç« å¼€å§‹ã€‚"
        
        print("\nğŸš€ å¼€å§‹æ’°å†™æ­£æ–‡...")
        for i, chapter in enumerate(self.outline):

            title = chapter.get('title')
            instruction = chapter.get('instruction', 'æ’°å†™æœ¬éƒ¨åˆ†å†…å®¹')

            print(f"[{i+1}/{len(self.outline)}] æ­£åœ¨æ’°å†™: {chapter}...")
            
            # TODO: æ„é€  Promptï¼Œæ ¸å¿ƒåœ¨äº Context çš„æ³¨å…¥
            # prompt = f"""
            # ä½ æ˜¯ä¸€ä½ä¸“ä¸šä½œå®¶ã€‚è¯·æ’°å†™ç« èŠ‚ï¼š"{chapter}"ã€‚
            #
            # ã€å‰æƒ…æè¦ã€‘ï¼š
            # {previous_summary}
            #
            # è¦æ±‚ï¼š
            # 1. å†…å®¹å……å®ï¼Œå­—æ•°çº¦ 800 å­—ã€‚
            # 2. å¿…é¡»æ‰¿æ¥ã€å‰æƒ…æè¦ã€‘çš„é€»è¾‘ï¼Œä¸è¦é‡å¤ã€‚
            # """
            system_prompt = (
                f"ä½ æ˜¯ä¸€åä¸“ä¸šä½œå®¶ï¼Œæ­£åœ¨æ’°å†™å…³äºã€Š{self.topic}ã€‹çš„é•¿æ–‡ã€‚\n"
                f"è¿™æ˜¯å…¨æ–‡å¤§çº²ï¼ˆç”¨äºæŠŠæ§æ•´ä½“è¿›åº¦ï¼‰ï¼š\n{outline_str}\n"
            )

            user_prompt = f"""
                        å½“å‰ä»»åŠ¡ï¼šæ’°å†™ç« èŠ‚ "{title}"ã€‚
                        å†™ä½œæŒ‡å¯¼ï¼š{instruction}

                        === ä¸Šæ–‡å›é¡¾ (Context) ===
                        ...{previous_summary}
                        === å›é¡¾ç»“æŸ ===

                        è¦æ±‚ï¼š
                        1. æ¥ç€ã€ä¸Šæ–‡å›é¡¾ã€‘çš„è¯­æ°”ç»§ç»­å†™ï¼Œä¿æŒé€»è¾‘è¿è´¯ã€‚
                        2. å†…å®¹è¦è¯¦å®ï¼Œå­—æ•°æ§åˆ¶åœ¨ 800 å­—å·¦å³ã€‚
                        3. ç›´æ¥è¾“å‡ºæ­£æ–‡å†…å®¹ï¼Œä¸è¦è¾“å‡ºæ ‡é¢˜ã€‚
                        """
            
            # try:
            #     response = client.chat.completions.create(
            #         model=MODEL_NAME,  # ä½¿ç”¨é…ç½®çš„æ¨¡å‹å
            #         messages=[{"role": "user", "content": prompt}],
            #         temperature=0.7
            #     )
            try:
                response = client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7
                )
                content = response.choices[0].message.content
                # self.articles.append(f"## {chapter}\n\n{content}")
                self.articles.append(f"## {title}\n\n{content}")
                
                # TODO: æ›´æ–° Context (æ ¸å¿ƒè€ƒå¯Ÿç‚¹)
                # ç®€å•ç­–ç•¥ï¼šæˆªå–æœ€å 200 å­—
                # ä¸ºäº†ä¸çˆ† Tokenï¼Œåªä¿ç•™æœ¬æ®µçš„æœ€å N ä¸ªå­—ç¬¦ä½œä¸ºä¸‹ä¸€æ®µçš„å¼•å­
                # -----------------------------------------------------------
                # æˆªå–æœ€å 500 ä¸ªå­—ç¬¦ã€‚
                # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šä¸éœ€è¦çŸ¥é“ 5000 å­—ä¹‹å‰å†™äº†å•¥ï¼Œåªéœ€è¦çŸ¥é“æœ€åä¸€æ®µè¯æ˜¯ä»€ä¹ˆï¼Œ
                # å°±èƒ½æ¥å¾—ä¸Šè¯­æ°”ã€‚

                if len(content) > 500:
                    previous_summary = content[-500:]
                else:
                    previous_summary = content
                # ç®€å•çš„é˜²é¢‘æ§
                time.sleep(1)
                # previous_summary = content[-200:]
                
            # except Exception as e:
            #     print(f"âš ï¸ ç« èŠ‚ {chapter} ç”Ÿæˆå¤±è´¥: {e}")
            except Exception as e:
                print(f"âš ï¸ ç« èŠ‚ {title} ç”Ÿæˆå¤±è´¥: {e}")

    def save_result(self):
        if not self.articles:
            print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•å†…å®¹")
            return
            
        filename = "final_article.md"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(f"# {self.topic}\n\n")
            f.write("\n\n".join(self.articles))
        print(f"\nğŸ‰ æ–‡ç« å·²ä¿å­˜è‡³ {filename}")

if __name__ == "__main__":
    print(f"ğŸ”Œ Endpoint: {BASE_URL}")
    print(f"ğŸ§  Model: {MODEL_NAME}\n")
    
    agent = LongArticleAgent("2025å¹´ DeepSeek å¯¹ AI è¡Œä¸šçš„å½±å“")
    agent.step1_generate_outline()
    agent.step2_generate_content_loop()
    agent.save_result()